# Filebeat Playbook - AWX Variables Guide

## üìã H∆∞·ªõng d·∫´n ƒëi·ªÅn Variables cho AWX

File playbook: `playbook-filebeat.yml`

---

## üîß AWX Extra Variables

### C·∫•u h√¨nh c∆° b·∫£n (Kafka Output - M·∫∑c ƒë·ªãnh)

```yaml
# Phi√™n b·∫£n Filebeat
filebeat_version: "8.x"

# C·∫•u h√¨nh Input
input_type: "filestream"
input_id: "filebeat-nginx-prod"
input_enabled: true

# ƒê∆∞·ªùng d·∫´n log files
log_paths:
  - /var/log/nginx/*error*.log
  - /var/log/nginx/*/*error*.log
  - /var/log/nginx/*access*.log
  - /var/log/nginx/*/*access*.log

# System logs (optional)
enable_system_logs: false
system_log_paths:
  - /var/log/messages
  - /var/log/syslog
  - /var/log/*.log

# Output Type
output_type: "kafka"

# Kafka Configuration
kafka_enabled: true
kafka_hosts:
  - "192.168.23.80:9092"
kafka_topic: "native-beat"
kafka_username: "kafka-admin"
kafka_password: "Thinhphat123"
kafka_sasl_mechanism: "SCRAM-SHA-512"
kafka_client_id: "beats-{{ inventory_hostname }}"
kafka_required_acks: 1

# Tags v√† Environment
filebeat_tags:
  - nginx
  - prod
filebeat_environment: "production"
shipper_name: ""

# Processors
enable_processors: true
add_host_metadata: true
add_cloud_metadata: true
add_docker_metadata: true
add_kubernetes_metadata: true

# Template Settings
index_number_of_shards: 1

# Service Configuration
filebeat_service_state: "started"
filebeat_service_enabled: true

# Modules (optional)
enable_modules: false
modules_reload_enabled: false

# Kibana (optional)
kibana_enabled: false
kibana_host: ""
setup_dashboards: false
```

---

## üìä Chi ti·∫øt t·ª´ng Variable

### **1. Filebeat Version**
```yaml
filebeat_version: "8.x"  # Ho·∫∑c "7.x"
```
- Phi√™n b·∫£n Filebeat c·∫ßn c√†i ƒë·∫∑t
- Options: `"7.x"` ho·∫∑c `"8.x"`

---

### **2. Input Configuration**

#### `input_type`
```yaml
input_type: "filestream"
```
- Lo·∫°i input ƒë·ªÉ ƒë·ªçc log files
- Options: `"filestream"` (khuy·∫øn ngh·ªã) ho·∫∑c `"log"`

#### `input_id`
```yaml
input_id: "filebeat-nginx-prod"
```
- ID duy nh·∫•t cho input configuration
- C√≥ th·ªÉ d√πng: `"filebeat-{{ inventory_hostname }}"` ƒë·ªÉ t·ª± ƒë·ªông theo hostname

#### `input_enabled`
```yaml
input_enabled: true
```
- B·∫≠t/t·∫Øt input
- Options: `true` ho·∫∑c `false`

#### `log_paths`
```yaml
log_paths:
  - /var/log/nginx/*error*.log
  - /var/log/nginx/*access*.log
```
- Danh s√°ch ƒë∆∞·ªùng d·∫´n file log c·∫ßn thu th·∫≠p
- Support glob patterns (`*`, `**`)
- V√≠ d·ª• kh√°c:
  ```yaml
  log_paths:
    - /var/log/app/*.log
    - /opt/application/logs/*.log
  ```

---

### **3. System Logs (Optional)**

#### `enable_system_logs`
```yaml
enable_system_logs: false
```
- B·∫≠t/t·∫Øt thu th·∫≠p system logs
- Options: `true` ho·∫∑c `false`

#### `system_log_paths`
```yaml
system_log_paths:
  - /var/log/messages
  - /var/log/syslog
```
- Ch·ªâ ho·∫°t ƒë·ªông khi `enable_system_logs: true`

---

### **4. Output Type**

#### `output_type`
```yaml
output_type: "kafka"
```
- Lo·∫°i output
- Options: `"kafka"`, `"elasticsearch"`, `"logstash"`

---

### **5. Kafka Output Configuration**

#### `kafka_enabled`
```yaml
kafka_enabled: true
```
- B·∫≠t/t·∫Øt Kafka output
- Options: `true` ho·∫∑c `false`

#### `kafka_hosts`
```yaml
kafka_hosts:
  - "192.168.23.80:9092"
  - "192.168.23.81:9092"  # Multiple brokers
```
- Danh s√°ch Kafka brokers
- Format: `["host:port", "host:port"]`

#### `kafka_topic`
```yaml
kafka_topic: "native-beat"
```
- T√™n Kafka topic ƒë·ªÉ g·ª≠i logs

#### `kafka_username`
```yaml
kafka_username: "kafka-admin"
```
- Username ƒë·ªÉ authentication v·ªõi Kafka

#### `kafka_password`
```yaml
kafka_password: "Thinhphat123"
```
- Password ƒë·ªÉ authentication v·ªõi Kafka
- **Khuy·∫øn ngh·ªã**: D√πng AWX Credential thay v√¨ hardcode

#### `kafka_sasl_mechanism`
```yaml
kafka_sasl_mechanism: "SCRAM-SHA-512"
```
- SASL mechanism
- Options: `"SCRAM-SHA-256"`, `"SCRAM-SHA-512"`, `"PLAIN"`

#### `kafka_client_id`
```yaml
kafka_client_id: "beats-{{ inventory_hostname }}"
```
- Client ID ƒë·ªÉ identify trong Kafka
- C√≥ th·ªÉ d√πng bi·∫øn Ansible: `{{ inventory_hostname }}`, `{{ ansible_hostname }}`

#### `kafka_required_acks`
```yaml
kafka_required_acks: 1
```
- S·ªë l∆∞·ª£ng acks c·∫ßn t·ª´ Kafka
- Options: 
  - `0`: Kh√¥ng ch·ªù ack
  - `1`: Ch·ªù ack t·ª´ leader
  - `-1`: Ch·ªù ack t·ª´ t·∫•t c·∫£ replicas

---

### **6. Elasticsearch Output Configuration**

Ch·ªâ c·∫ßn khi `output_type: "elasticsearch"`

```yaml
elasticsearch_enabled: true
elasticsearch_hosts:
  - "https://192.168.17.56:9200"
elasticsearch_username: "elastic"
elasticsearch_password: "your-password"
elasticsearch_protocol: "https"  # ho·∫∑c "http"
elasticsearch_ssl_fingerprint: "4d7770fa504fcf0f027c0413a699e032f2bbe740eccb54b1056767478be6d567"
```

---

### **7. Logstash Output Configuration**

Ch·ªâ c·∫ßn khi `output_type: "logstash"`

```yaml
logstash_enabled: true
logstash_hosts:
  - "logstash-01:5044"
  - "logstash-02:5044"
```

---

### **8. Kibana Setup (Optional)**

```yaml
kibana_enabled: false
kibana_host: ""
setup_dashboards: false
```

V√≠ d·ª• khi enable:
```yaml
kibana_enabled: true
kibana_host: "192.168.17.56:5601"
setup_dashboards: true
```

---

### **9. General Settings**

#### `filebeat_environment`
```yaml
filebeat_environment: "production"
```
- T√™n environment, ƒë∆∞·ª£c th√™m v√†o m·ªói log event
- V√≠ d·ª•: `"production"`, `"staging"`, `"development"`

#### `shipper_name`
```yaml
shipper_name: ""
```
- T√™n c·ªßa shipper (optional)
- ƒê·ªÉ tr·ªëng ho·∫∑c ƒë·∫∑t t√™n: `"filebeat-prod-server"`

#### `filebeat_tags`
```yaml
filebeat_tags:
  - nginx
  - prod
```
- Tags ƒë·ªÉ ph√¢n lo·∫°i logs
- V√≠ d·ª• kh√°c: `["application", "java", "prod"]`

---

### **10. Processors**

#### `enable_processors`
```yaml
enable_processors: true
```
- B·∫≠t/t·∫Øt t·∫•t c·∫£ processors

#### `add_host_metadata`
```yaml
add_host_metadata: true
```
- Th√™m th√¥ng tin host (hostname, OS, IP, etc.)

#### `add_cloud_metadata`
```yaml
add_cloud_metadata: true
```
- Th√™m cloud metadata (AWS, Azure, GCP)

#### `add_docker_metadata`
```yaml
add_docker_metadata: true
```
- Th√™m Docker container metadata

#### `add_kubernetes_metadata`
```yaml
add_kubernetes_metadata: true
```
- Th√™m Kubernetes metadata

---

### **11. Template Settings**

#### `index_number_of_shards`
```yaml
index_number_of_shards: 1
```
- S·ªë l∆∞·ª£ng shards cho Elasticsearch index

---

### **12. Service Configuration**

#### `filebeat_service_state`
```yaml
filebeat_service_state: "started"
```
- State c·ªßa Filebeat service
- Options: `"started"`, `"stopped"`, `"restarted"`

#### `filebeat_service_enabled`
```yaml
filebeat_service_enabled: true
```
- Enable service khi boot
- Options: `true` ho·∫∑c `false`

---

### **13. Modules (Optional)**

#### `enable_modules`
```yaml
enable_modules: false
```
- B·∫≠t/t·∫Øt Filebeat modules

#### `modules_reload_enabled`
```yaml
modules_reload_enabled: false
```
- Auto reload modules khi c√≥ thay ƒë·ªïi

---

## üéØ V√≠ d·ª• Scenarios

### **Scenario 1: Nginx Logs ‚Üí Kafka (Production)**

```yaml
filebeat_version: "8.x"
input_id: "filebeat-nginx-prod"
log_paths:
  - /var/log/nginx/*error*.log
  - /var/log/nginx/*access*.log
output_type: "kafka"
kafka_hosts: ["192.168.23.80:9092"]
kafka_topic: "nginx-prod"
kafka_username: "kafka-admin"
kafka_password: "Thinhphat123"
filebeat_environment: "production"
filebeat_tags: ["nginx", "prod"]
```

---

### **Scenario 2: Application Logs ‚Üí Kafka (Staging)**

```yaml
filebeat_version: "8.x"
input_id: "filebeat-app-staging"
log_paths:
  - /opt/app/logs/*.log
  - /var/log/app/*.log
enable_system_logs: true
output_type: "kafka"
kafka_hosts: ["192.168.23.80:9092"]
kafka_topic: "app-staging"
filebeat_environment: "staging"
filebeat_tags: ["application", "staging"]
```

---

### **Scenario 3: All Logs ‚Üí Elasticsearch**

```yaml
filebeat_version: "8.x"
log_paths:
  - /var/log/*.log
enable_system_logs: true
output_type: "elasticsearch"
elasticsearch_enabled: true
elasticsearch_hosts: ["https://es-cluster:9200"]
elasticsearch_username: "elastic"
elasticsearch_password: "password"
kibana_enabled: true
kibana_host: "kibana:5601"
setup_dashboards: true
filebeat_environment: "production"
```

---

### **Scenario 4: Multi-environment v·ªõi tags kh√°c nhau**

**Production:**
```yaml
filebeat_environment: "production"
kafka_topic: "prod-logs"
filebeat_tags: ["prod"]
```

**Staging:**
```yaml
filebeat_environment: "staging"
kafka_topic: "staging-logs"
filebeat_tags: ["staging"]
```

**Development:**
```yaml
filebeat_environment: "development"
kafka_topic: "dev-logs"
filebeat_tags: ["dev"]
```

---

## üîí Security Note

**Kh√¥ng n√™n hardcode passwords trong Extra Variables!**

S·ª≠ d·ª•ng AWX Credentials:
1. T·∫°o Custom Credential Type cho Kafka
2. Store `kafka_password` trong Credential
3. Inject v√†o playbook t·ª± ƒë·ªông

---

## ‚úÖ Variables c·∫ßn thi·∫øt t·ªëi thi·ªÉu

ƒê·ªÉ ch·∫°y playbook, ch·ªâ c·∫ßn:

```yaml
# B·∫Øt bu·ªôc
output_type: "kafka"
kafka_hosts: ["192.168.23.80:9092"]
kafka_topic: "native-beat"
kafka_username: "kafka-admin"
kafka_password: "Thinhphat123"

# Optional nh∆∞ng n√™n c√≥
filebeat_environment: "production"
filebeat_tags: ["nginx", "prod"]
```

C√°c variables c√≤n l·∫°i s·∫Ω d√πng gi√° tr·ªã m·∫∑c ƒë·ªãnh t·ª´ playbook.
